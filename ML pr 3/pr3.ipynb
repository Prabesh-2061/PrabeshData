{"cells":[{"source":"![dvd_image](dvd_image.jpg)\n\nA DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n\nThe data they provided is in the csv file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"amount_2\"`: The square of `\"amount\"`.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Lenght of the movie being rented, in minuites.\n- `\"length_2\"`: The square of `\"length\"`.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped.","metadata":{},"id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Import any additional modules and start coding below\ndf =  pd.read_csv('rental_info.csv')\n\ndf['rental_date']= pd.to_datetime(df['rental_date'])\ndf['return_date']= pd.to_datetime(df['return_date'])\n# print(df.info())\n\ndf['rental_length_days'] = (df['return_date'] - df['rental_date']).dt.days\n# print(df[['rental_date','return_date','rental_length_days' ]])\n\nprint(df.columns)\nprint(df['special_features'].value_counts())\ndf['deleted_scenes']  =df['special_features'].apply(lambda x : 1 if 'Deleted Scenes' in x  else 0)\ndf['behind_the_scenes'] = df['special_features'].apply(lambda x : 1 if 'Behind the Scenes' in x  else 0)\nprint(df[['deleted_scenes','behind_the_scenes']])\n","metadata":{"executionCancelledAt":null,"executionTime":82,"lastExecutedAt":1741257821195,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Import any additional modules and start coding below\ndf =  pd.read_csv('rental_info.csv')\n\ndf['rental_date']= pd.to_datetime(df['rental_date'])\ndf['return_date']= pd.to_datetime(df['return_date'])\n# print(df.info())\n\ndf['rental_length_days'] = (df['return_date'] - df['rental_date']).dt.days\n# print(df[['rental_date','return_date','rental_length_days' ]])\n\nprint(df.columns)\nprint(df['special_features'].value_counts())\ndf['deleted_scenes']  =df['special_features'].apply(lambda x : 1 if 'Deleted Scenes' in x  else 0)\ndf['behind_the_scenes'] = df['special_features'].apply(lambda x : 1 if 'Behind the Scenes' in x  else 0)\nprint(df[['deleted_scenes','behind_the_scenes']])\n","lastExecutedByKernel":"717224e9-b57c-4e9a-8324-762cd494a0e6","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"a7ede566-910a-445c-b11a-68d192ac8506","cell_type":"code","execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":"Index(['rental_date', 'return_date', 'amount', 'release_year', 'rental_rate',\n       'length', 'replacement_cost', 'special_features', 'NC-17', 'PG',\n       'PG-13', 'R', 'amount_2', 'length_2', 'rental_rate_2',\n       'rental_length_days'],\n      dtype='object')\n{Trailers,Commentaries,\"Behind the Scenes\"}                     1308\n{Trailers}                                                      1139\n{Trailers,Commentaries}                                         1129\n{Trailers,\"Behind the Scenes\"}                                  1122\n{\"Behind the Scenes\"}                                           1108\n{Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}             1101\n{Commentaries}                                                  1089\n{Commentaries,\"Behind the Scenes\"}                              1078\n{Trailers,\"Deleted Scenes\"}                                     1047\n{\"Deleted Scenes\",\"Behind the Scenes\"}                          1035\n{\"Deleted Scenes\"}                                              1023\n{Commentaries,\"Deleted Scenes\"}                                 1011\n{Trailers,Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}     983\n{Trailers,Commentaries,\"Deleted Scenes\"}                         916\n{Trailers,\"Deleted Scenes\",\"Behind the Scenes\"}                  772\nName: special_features, dtype: int64\n       deleted_scenes  behind_the_scenes\n0                   0                  1\n1                   0                  1\n2                   0                  1\n3                   0                  1\n4                   0                  1\n...               ...                ...\n15856               1                  1\n15857               1                  1\n15858               1                  1\n15859               1                  1\n15860               1                  1\n\n[15861 rows x 2 columns]\n"}]},{"source":"from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Assuming df is already defined\nX1 = df.drop(columns=['rental_length_days', 'return_date', 'rental_date', 'special_features'])\nX = X1\ny = df['rental_length_days']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nlas = Lasso(alpha=0.2)\nlas.fit(X_train_scaled, y_train)\ncoef = las.coef_\n\n# Convert numpy arrays back to DataFrame to use iloc\nX_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n\nX_train1 = X_train_scaled_df.iloc[:, coef > 0]\nX_test1 = X_test_scaled_df.iloc[:, coef > 0]","metadata":{"executionCancelledAt":null,"executionTime":328,"lastExecutedAt":1741257821523,"lastExecutedByKernel":"717224e9-b57c-4e9a-8324-762cd494a0e6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Assuming df is already defined\nX1 = df.drop(columns=['rental_length_days', 'return_date', 'rental_date', 'special_features'])\nX = X1\ny = df['rental_length_days']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nlas = Lasso(alpha=0.2)\nlas.fit(X_train_scaled, y_train)\ncoef = las.coef_\n\n# Convert numpy arrays back to DataFrame to use iloc\nX_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n\nX_train1 = X_train_scaled_df.iloc[:, coef > 0]\nX_test1 = X_test_scaled_df.iloc[:, coef > 0]"},"cell_type":"code","id":"8122b6ed-db7a-4132-9818-2c65b1b97ed0","outputs":[],"execution_count":79},{"source":"print(df.info)","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1741257821577,"lastExecutedByKernel":"717224e9-b57c-4e9a-8324-762cd494a0e6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(df.info)","outputsMetadata":{"0":{"height":311,"type":"stream"}}},"cell_type":"code","id":"acc9b0dc-5349-40fe-bd3b-f34a5e07053e","outputs":[{"output_type":"stream","name":"stdout","text":"<bound method DataFrame.info of                     rental_date  ... behind_the_scenes\n0     2005-05-25 02:54:33+00:00  ...                 1\n1     2005-06-15 23:19:16+00:00  ...                 1\n2     2005-07-10 04:27:45+00:00  ...                 1\n3     2005-07-31 12:06:41+00:00  ...                 1\n4     2005-08-19 12:30:04+00:00  ...                 1\n...                         ...  ...               ...\n15856 2005-08-22 10:49:15+00:00  ...                 1\n15857 2005-07-31 09:48:49+00:00  ...                 1\n15858 2005-08-20 10:35:30+00:00  ...                 1\n15859 2005-07-31 13:10:20+00:00  ...                 1\n15860 2005-08-18 06:33:55+00:00  ...                 1\n\n[15861 rows x 18 columns]>\n"}],"execution_count":80},{"source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nlr = LinearRegression()\nlr.fit(X_train1,y_train)\ny_pred = lr.predict(X_test1)\nmse_lr = mean_squared_error(y_test,y_pred)\n\nparam_grid = { 'max_depth': np.arange(1,200,1),\n              'min_samples_leaf': np.arange(0,1,0.2),\n              'max_depth': np.arange(1,20,1)\n    \n}\nran = RandomizedSearchCV(estimator=DecisionTreeRegressor(), param_distributions= param_grid, random_state= 9)\nran.fit(X_train1,y_train)\nbest_dt = ran.best_estimator_\nbest_dt.fit(X_train,y_train)\ny_pred1 = best_dt.predict(X_test)\nmse_dt = mean_squared_error(y_test,y_pred)\n\nparam_grid1 = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)\n    \n}\nrad1 = RandomizedSearchCV(estimator=RandomForestRegressor(),param_distributions= param_grid1 , random_state = 9 )\nrad1.fit(X_train1, y_train)\nbest_rf = rad1.best_estimator_\nbest_rf.fit(X_train,y_train)\ny_pred_ra = best_rf.predict(X_test)\n\nmse_rf = mean_squared_error(y_test,y_pred_ra)\n\nbest_model = RandomForestRegressor()\nbest_mse = mse_rf\n\n","metadata":{"executionCancelledAt":null,"executionTime":5215,"lastExecutedAt":1741257826792,"lastExecutedByKernel":"717224e9-b57c-4e9a-8324-762cd494a0e6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nlr = LinearRegression()\nlr.fit(X_train1,y_train)\ny_pred = lr.predict(X_test1)\nmse_lr = mean_squared_error(y_test,y_pred)\n\nparam_grid = { 'max_depth': np.arange(1,200,1),\n              'min_samples_leaf': np.arange(0,1,0.2),\n              'max_depth': np.arange(1,20,1)\n    \n}\nran = RandomizedSearchCV(estimator=DecisionTreeRegressor(), param_distributions= param_grid, random_state= 9)\nran.fit(X_train1,y_train)\nbest_dt = ran.best_estimator_\nbest_dt.fit(X_train,y_train)\ny_pred1 = best_dt.predict(X_test)\nmse_dt = mean_squared_error(y_test,y_pred)\n\nparam_grid1 = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)\n    \n}\nrad1 = RandomizedSearchCV(estimator=RandomForestRegressor(),param_distributions= param_grid1 , random_state = 9 )\nrad1.fit(X_train1, y_train)\nbest_rf = rad1.best_estimator_\nbest_rf.fit(X_train,y_train)\ny_pred_ra = best_rf.predict(X_test)\n\nmse_rf = mean_squared_error(y_test,y_pred_ra)\n\nbest_model = RandomForestRegressor()\nbest_mse = mse_rf\n\n"},"cell_type":"code","id":"74ab0e82-b8c3-4980-a626-94205b7f24e1","outputs":[],"execution_count":81},{"source":"print(mse_lr)\n# print(lr.get_params())\n# print(RandomForestRegressor().get_params())\nprint(best_dt, mse_dt)\nprint(best_rf , mse_rf)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1741257826841,"lastExecutedByKernel":"717224e9-b57c-4e9a-8324-762cd494a0e6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(mse_lr)\n# print(lr.get_params())\n# print(RandomForestRegressor().get_params())\nprint(best_dt, mse_dt)\nprint(best_rf , mse_rf)","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"de45a838-a3ea-4296-83c5-1707a009fedb","outputs":[{"output_type":"stream","name":"stdout","text":"4.845903109515722\nDecisionTreeRegressor(max_depth=10, min_samples_leaf=0.2) 4.845903109515722\nRandomForestRegressor(max_depth=6, n_estimators=78) 2.456541867411209\n"}],"execution_count":82}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}